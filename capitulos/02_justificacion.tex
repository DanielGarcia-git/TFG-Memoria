\chapter{Justificación}
\label{cap:justificacion}

% Corregido 31/12/2023
% TODO:daniel: Revisar la justificación

En este capítulo se explicara cuál es el problema a resolver, las alternativas que hay
en el mercado y la solución que se tomara en este proyecto.

\section{Identificación del problema}
\label{sec:problema}

% Corregido
% TODO:daniel: Revisar la sección de identificación del problema

Como he explicado en el capítulo \ref{cap:introducion} la ingeniería inversa es aplicada
en una infinidad de campos y de los cuales hoy en día es utilizada. Pero como he
mencionado aplicar ingeniería inversa no es una tarea fácil, ya que actualmente los
programas que podemos encontrar en el mercado son de tal complejidad que aplicar
ingeniería inversa sobre la totalidad del programa supone horas y horas de trabajo,
teniendo el riesgo de que los resultados obtenidos no se asemejen a la realidad.

Esta complejidad no solo viene dada por el gran tamaño de los programas actuales, sino
de las técnicas que se utilizan para poder ocultar aún más el programa original. Algunas
de estas técnicas son \textit{constant blinding}\footnote{Esta técnica consiste en poner
un valor aleatorio a las constantes (a través de operaciones como la XOR)}, cambiar el
encoding de las variables\footnote{Busca la ocultación del valor de la variable cambiando
su representación de datos}, agregación de datos\footnote{Busca agrupar variables del mismo
tipo, por ejemplo bajo un \textit{struct}}, separación de datos\footnote{Al contrario que
la agregación de datos, esta busca separar los datos en unidades más pequeñas, por ejemplo
de un \textit{short} a un \textit{char}}, \textit{dead code insertion}\footnote{Agregar
código redundante al programa}, \textit{loop unrolling}\footnote{Es una tecnica que aplican
los compiladores que además de disminuir el coste computacional del programa hace que el
código sea menos legible}, entre otras. \cite{TecnicasIlegibleBinario}

También a la hora de aplicar ingeniería inversa debemos sumar la complejidad de las aplicaciones
distribuidas, es decir, antes, cuando disponíamos de un programa disponíamos de su código en
su totalidad, aunque este fuese en forma de un binario. Con las aplicaciones distribuidas, el
programa se ha segmentado en diferentes partes y estas partes cada una se puede encontrar en una
máquina diferente, provocando que no dispongamos a veces del todo el programa y, por lo tanto,
de todo su diseño y lógica.

En consecuencia, debido a las técnicas de ocultación de código, las optimizaciones que el compilador
puede aplicar sobre el código, el gran tamaño de los programas modernos y el auge de las aplicaciones
distribuidas hacen que la tarea de aplicar ingeniería inversa sobre un programa sea muy compleja y
que las soluciones actuales, que detallaré en la sección \ref{sec:alternativas}, no son capaces de dar
buenos resultados, sino que dan una especie de pseudocódigo que nos puede ayudar a entender la lógica
del programa.

Todos estos factores contribuyen a que aplicar ingeniería inversa sea muy complejo y costoso y, por
lo tanto, inviable en muchos casos para ciertos escenarios.

\section{Solucion tomada}
\label{sec:solucion}

% Corregido
% TODO:daniel: Revisar la sección de solución tomada

Una vez visto en la sección \ref{sec:alternativas} las diferentes alternativas que hay
en el mercado para poder aplicar ingeniería inversa sobre fichero ejecutable y observado
que los resultados obtenidos no son un código en C compilable y realista, quiero explicar
cuál es la solución que en este proyecto se desarrollara.

El objetivo es a través de un ejecutable desamblado poder generar un código en C compilable
y lo más fiel al original. Para ello queremos de asistirnos de la inteligencia artificial
de tal manera que si le damos un código desamblado esta nos pueda devolver un código en C.
Más concretamente, queremos utilizar inteligencias artificiales basadas en redes neuronales
del estilo de ChatGPT\footnote{ChatGPT es una aplicación de chatbot de inteligencia artificial
desarrollado en 2022 por OpenAI que se especializa en el diálogo} o modelos similares como 
Llama\footnote{LLaMA (Large Language Model Meta AI) es un gran modelo de lenguaje (LLM) 
lanzado por Meta AI en febrero de 2023}.

Por lo tanto, lo que se pretende en esta solución es poder mejorar los resultados de decompiladores
que hay en el mercado, asistiéndonos con inteligencia artificial, la cual ha demostrado
que a pesar de haber sido entrenadas para hacer una única tarea en concreto (los modelos anteriores
por ejemplo, han sido entrenados exclusivamente para completar frases) son capaces de
realizar otro tipo de tareas a las cuales no han sido entrenadas y con resultados bastante buenos.
Además, están pueden ser reentrenadas para mejorar los resultados.
