\chapter{Trabajo futuro}
\label{cap:trabajo_futuro}

En este capítulo se presentan las posibles líneas de trabajo futuro que se pueden seguir
para mejorar los resultados obtenidos en este trabajo. Estas líneas de trabajo futuro
van ligadas con las limitaciones que el proyecto tiene y que se han presentado a lo largo
de la memoria.

Una de las lineas de trabajo futuro que se pueden seguir es utilizar modelos de lenguaje
más grandes y más potentes. En este trabajo se ha utilizado un modelo de 3 billones de parámetros,
que aunque parece un numero muy grande, ya se ha quedado pequeño comparado con modelos de
175 billones de parámetros como es el caso de GPT-3. Principalemente, en este proyecto la
limitación de utilizar modelos de lenguaje más grandes es el coste computacional que supone
entrenarlos. Por lo tanto, se deberá de utilizar entornos de entrenamiento más potentes
con GPU's mas potentes, de almenos 24GB de memoria VRAM.

Otra de las líneas de trabajo futuro que se pueden seguir es utilizar un conjunto de entrenamiento
más grande. En este trabajo se ha utilizado un conjunto de entrenamiento pequeño y de poca variedad
debido a la complejidad de obtener un conjunto de entrenamiento mas grande y balanceado para optimizar
el aprendizaje del modelo de lenguaje.

Así mismo, seria interesante utilizar metodos de preprocesamiento de los datos de entrada de tal manera
que podamos facilitar el entendimiento y disminuir la complejidad del problema al modelo de lenguaje.
De manera que podamos obtener mejores resultados con un conjunto de entrenamiento más pequeño.