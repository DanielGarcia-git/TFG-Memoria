\chapter{Resultados}
\label{cap:resultados}

% Corregido 02/01/2023
% Revisado 14/01/2024

En este capítulo se presentan los resultados obtenidos en el desarrollo de este trabajo. 
En la sección \ref{sec:evaluacion} se describe la metodología de evaluación utilizada 
para medir el desempeño de los modelos. En la sección \ref{sec:resultados_finales} se
presentan los resultados finales obtenidos con el modelo \textit{Stable Code} después 
de realizarle un \textit{fine-tuning}. Finalmente, en la sección \ref{sec:analisis_resultados}
se realiza un análisis de los resultados obtenidos.

\section{Metodología de evaluación}
\label{sec:evaluacion}

% Corregido 08/01/2024
% Revisado 14/01/2024

Para poder evaluar la calidad de los resultados se han definido una serie de criterios que
nos permitirán evaluar los resultados obtenidos. Estos criterios son los siguientes:

\begin{enumerate}
    \item \textbf{Criterio 1:} el modelo debe de ser capaz de generar código en C que sea
        compilable y ejecutable.
    \item \textbf{Criterio 2:} el modelo debe de ser capaz de generar código en C que sea
        funcionalmente correcto.
\end{enumerate}

Por lo tanto, si el resultado cumple con el primer criterio, diremos que es un resultado aceptable,
ya que ha generado un código sintácticamente correcto. Si el resultado cumple con el segundo criterio
diremos que es un resultado excelente, ya que ha generado un código sintácticamente correcto y funcionalmente
correcto. Si no cumple con ninguno de los dos criterios, diremos que es un resultado malo.

\section{Resultados finales}
\label{sec:resultados_finales}

% Corregido 10/01/2024
% Revisado 14/01/2024

Después de haber ejecutado el \textit{fine-tuning} de nuestro modelo, vamos a hacer las mismas pruebas
que hicimos en el capítulo \ref{cap:viabilidad_hipotesis} para comprobar si el modelo es capaz de
generar código en C que sea compilable y ejecutable. Para ello, vamos a utilizar el mismo conjunto
de datos. Diferenciare entre las diferentes estrategias de entrenamiento definidas en el capítulo
\ref{cap:estrategia_entrenamiento}.

Para poder comprobar el resultado lanzaremos el comando que se describe en el código \ref{code:comando_lora},
en la parte de la opcion \mintinline{bash}|--prompt| pondremos el siguiente texto:

\begin{quote}
    \textit{``Below is an instruction that describes a task, paired with an input that provides further context.
    Write a response that appropriately completes the request. \newline
    Instruction: Generates C code from this assembler code \newline
    Input: \textbf{El codigo en ensamblador}\newline
    Response:''}
\end{quote}

Así mismo iremos cambiando los directorios de estrategia dependiendo de que estrategia estemos probando
en cada momento.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
$HOME/soft/bin/python generate/lora.py 
    --prompt "" 
    --checkpoint_dir checkpoints/stabilityai/stablecode-completion-alpha-3b 
    --lora_path out/lora/Estrategia_1/lit_model_lora_finetuned.pth 
    \end{minted}
    \caption[Comando lanzado para generar una salida dado un \textit{prompt} utilizando los pesos refinados por el \textit{fine-tuning}]{Comando lanzado para generar una salida dado un \textit{prompt} utilizando los pesos refinados por el \textit{fine-tuning} (Elaboración propia)}
    \label{code:comando_lora}
\end{mycode}

\subsection{Cluster AC}
\label{subsec:cluster_ac}

\subsubsection{Estrategia 1}
\label{subsubsec:resultados:estrategia_1}

% Corregido 10/01/2024
% TODO:daniel: Revisar los resultados de la estrategia 1

Ejecutamos los comandos que se describen en el código \ref{code:comando_lora} para
la estrategia 1 y la prueba con el programa de \textit{Hello World} y obtenemos
las siguientes métricas de generación:

\begin{itemize}
    \item \textbf{Tiempo en instanciar el modelo:} 0.25 segundos
    \item \textbf{Tiempo en cargar los pesos del modelo:} 4.65 segundos
    \item \textbf{Tiempo de inferencia:} 3.31 segundos, 30.24 tokens por segundo
    \item \textbf{Memoria utilizada:} 2.20 GB
\end{itemize}

En el código \ref{code:Prueba1_Estrategia1_ClusterAC} podemos ver el resultado obtenido
en la primera prueba.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
The function endbr64 returns to the caller by following the function chain with the function endbr64, a function that returns an error code. The function endbr64 calls the function puts. The function puts calls puts with the argument line, which is a pointer to the line. The function puts calls the function puts, a function that calls  put to print the line. The function puts calls the function puts, a function that calls put to print the line. The
    \end{minted}
    \caption[Salida del modelo entrenado con la estrategia 1 y utilizando como entrada el programa de \textit{Hello World}]{Salida del modelo entrenado con la estrategia 1 y utilizando como entrada el programa de \textit{Hello World} (Elaboración propia)}
    \label{code:Prueba1_Estrategia1_ClusterAC}
\end{mycode}

Ejecutamos los comandos que se describen en el código \ref{code:comando_lora} para
la estrategia 1 y la prueba con el programa de \textit{Binary Search} y obtenemos
las siguientes métricas de generación:

\begin{itemize}
    \item \textbf{Tiempo en instanciar el modelo:} 0.25 segundos
    \item \textbf{Tiempo en cargar los pesos del modelo:} 4.66 segundos
    \item \textbf{Tiempo de inferencia:} 4.11 segundos, 24.33 tokens por segundo
    \item \textbf{Memoria utilizada:} 3.78 GB
\end{itemize}

En el código \ref{code:Prueba2_Estrategia1_ClusterAC} podemos ver el resultado obtenido
en la primera prueba.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
The function endbr64 returns the absolute value of the least significant bit of the value in EBX on success, and 1 on failure. On failure, endbr64 returns the value to the sign of the operand in EBX.

### Instruction:
The function mov ecx, EBX represents the value to the least significant bit of 8 byte at address EBX. The value in EBX is 1 on success, and 0 if the least significant
    \end{minted}
    \caption[Salida del modelo entrenado con la estrategia 1 y utilizando como entrada el programa de \textit{Binary Search}]{Salida del modelo entrenado con la estrategia 1 y utilizando como entrada el programa de \textit{Binary Search} (Elaboración propia)}
    \label{code:Prueba2_Estrategia1_ClusterAC}
\end{mycode}

\subsubsection{Estrategia 2}
\label{subsubsec:resultados:estrategia_2}

% Corregido 10/01/2024
% TODO:daniel: Revisar los resultados de la estrategia 2

Como he mencionado en el capítulo \ref{cap:estrategia_entrenamiento}, la estrategia 2
es una estrategia que se ha diseñado para intentar mejorar los resultados de la estrategia 1
y que se compone de dos conjuntos de entrenamiento, una más pequeño con 100 000 muestras y otro
que contiene alrededor de 500 000 muestras. En esta sección vamos a ver los resultados obtenidos
con la estrategia 2 usando estos dos conjuntos de entrenamiento y probando con los dos programas
de prueba.

\subsubsection{Conjunto de entrenamiento de 100 000 muestras}

Ejecutamos los comandos que se describen en el código \ref{code:comando_lora} para
la estrategia 2 y la prueba con el programa de \textit{Hello World} y obtenemos
las siguientes métricas de generación:

\begin{itemize}
    \item \textbf{Tiempo en instanciar el modelo:} 0.16 segundos
    \item \textbf{Tiempo en cargar los pesos del modelo:} 4.42 segundos
    \item \textbf{Tiempo de inferencia:} 2.56 segundos, 39.12 tokens por segundo
    \item \textbf{Memoria utilizada:} 5.82 GB
\end{itemize}

En el código \ref{code:Prueba1_Estrategia2_1_ClusterAC} podemos ver el resultado obtenido
en la primera prueba.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
void ncecl3e(struct sub_data * sub_data) { 
    sub_data = sub_data - 0x0b; 
    union sub_data * sub_data = sub_data - 0x0b; 
    sub_data - & sub_data - sub_data - sub_sub_data = - 0x4f800010b880000000e0000007d
}
    \end{minted}
    \caption[Salida del modelo entrenado con la estrategia 2 (100 000 muestras) y utilizando como entrada el programa de \textit{Hello World}]{Salida del modelo entrenado con la estrategia 2 (100 000 muestras) y utilizando como entrada el programa de \textit{Hello World} (Elaboración propia)}
    \label{code:Prueba1_Estrategia2_1_ClusterAC}
\end{mycode}

Ejecutamos los comandos que se describen en el código \ref{code:comando_lora} para
la estrategia 2 y la prueba con el programa de \textit{Binary Search} y obtenemos
las siguientes métricas de generación:

\begin{itemize}
    \item \textbf{Tiempo en instanciar el modelo:} 0.16 segundos
    \item \textbf{Tiempo en cargar los pesos del modelo:} 4.43 segundos
    \item \textbf{Tiempo de inferencia:} 3.16 segundos, 31.66 tokens por segundo
    \item \textbf{Memoria utilizada:} 7.58 GB
\end{itemize}

En el código \ref{code:Prueba2_Estrategia2_1_ClusterAC} podemos ver el resultado obtenido
en la primera prueba.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
%% % % rsp % rsp % rsp ***************************************************************** % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp rsp rsp % rsp % rsp rsp % rsp % rsp rsp % rsp % rsp % rsp rsp % rsp rsp % rsp % rsp % rsp % rsp rsp % rsp rsp % rsp % rsp rsp rsp % rsp % rn % rsp rsp % rsp % rsp % Resp % rsp % rsp % rsp rsp % rsp <%
    \end{minted}
    \caption[Salida del modelo entrenado con la estrategia 2 (100 000 muestras) y utilizando como entrada el programa de \textit{Binary Search}]{Salida del modelo entrenado con la estrategia 2 (100 000 muestras) y utilizando como entrada el programa de \textit{Binary Search} (Elaboración propia)}
    \label{code:Prueba2_Estrategia2_1_ClusterAC}
\end{mycode}

\subsubsection{Conjunto de entrenamiento de 500 000 muestras}

Ejecutamos los comandos que se describen en el código \ref{code:comando_lora} para
la estrategia 2 y la prueba con el programa de \textit{Hello World} y obtenemos
las siguientes métricas de generación:

\begin{itemize}
    \item \textbf{Tiempo en instanciar el modelo:} 0.15 segundos
    \item \textbf{Tiempo en cargar los pesos del modelo:} 4.37 segundos
    \item \textbf{Tiempo de inferencia:} 2.52 segundos, 39.65 tokens por segundo
    \item \textbf{Memoria utilizada:} 5.82 GB
\end{itemize}

En el código \ref{code:Prueba1_Estrategia2_2_ClusterAC} podemos ver el resultado obtenido
en la primera prueba.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
void ncecl3e(struct sub_data * sub_data) {
    sub_data = sub_data - 0x0b; union sub_data * sub_data = sub_data - 0x0b;
    sub_data - & sub_data - sub_data - sub_sub_data = - 0x4f800010b880000000e0000007d
}
    \end{minted}
    \caption[Salida del modelo entrenado con la estrategia 2 (500 000 muestras) y utilizando como entrada el programa de \textit{Hello World}]{Salida del modelo entrenado con la estrategia 2 (500 000 muestras) y utilizando como entrada el programa de \textit{Hello World} (Elaboración propia)}
    \label{code:Prueba1_Estrategia2_2_ClusterAC}
\end{mycode}

Ejecutamos los comandos que se describen en el código \ref{code:comando_lora} para
la estrategia 2 y la prueba con el programa de \textit{Binary Search} y obtenemos
las siguientes métricas de generación:

\begin{itemize}
    \item \textbf{Tiempo en instanciar el modelo:} 0.16 segundos
    \item \textbf{Tiempo en cargar los pesos del modelo:} 4.36 segundos
    \item \textbf{Tiempo de inferencia:} 3.17 segundos, 31.50 tokens por segundo
    \item \textbf{Memoria utilizada:} 7.58 GB
\end{itemize}

En el código \ref{code:Prueba2_Estrategia2_2_ClusterAC} podemos ver el resultado obtenido
en la primera prueba.

\begin{mycode}
    \begin{minted}[fontsize=\scriptsize]{c}
%% % % rsp % rsp % rsp ***************************************************************** % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp % rsp rsp rsp % rsp % rsp rsp % rsp % rsp rsp % rsp % rsp % rsp rsp % rsp rsp % rsp % rsp % rsp % rsp rsp % rsp rsp % rsp % rsp rsp rsp % rsp % rn % rsp rsp % rsp % rsp % Resp % rsp % rsp % rsp rsp % rsp <%
    \end{minted}
    \caption[Salida del modelo entrenado con la estrategia 2 (500 000 muestras) y utilizando como entrada el programa de \textit{Binary Search}]{Salida del modelo entrenado con la estrategia 2 (500 000 muestras) y utilizando como entrada el programa de \textit{Binary Search} (Elaboración propia)}
    \label{code:Prueba2_Estrategia2_2_ClusterAC}
\end{mycode}

\section{Análisis de resultados}
\label{sec:analisis_resultados}

Vista general de los resultados obtenidos y análisis de los mismos.